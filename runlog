diary on
run
1
--- Feature extraction and classification (Hollywood2) ---
Computing features for all videos in the training set:
1

2

3

4

5

6

7

8

9
{Operation terminated by user during <a href="matlab:helpUtils.errorDocCallback('activateNN', '/home/legend/ISA_SFA/activation_functions/activateNN.m', 31)" style="font-weight:bold">activateNN</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/activation_functions/activateNN.m',31,0)">line 31</a>)


In <a href="matlab:helpUtils.errorDocCallback('activateISA', '/home/legend/ISA_SFA/activation_functions/activateISA.m', 18)" style="font-weight:bold">activateISA</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/activation_functions/activateISA.m',18,0)">line 18</a>)
    act_w = activateNN(input(:, count+1:batchend),
    network_isa.W, single(0), @sq_vec);

In <a href="matlab:helpUtils.errorDocCallback('transact_dense_samp', '/home/legend/ISA_SFA/transact_dense_samp.m', 64)" style="font-weight:bold">transact_dense_samp</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/transact_dense_samp.m',64,0)">line 64</a>)
            act_isa_l1{i,j} = activateISA(X{j},
            isa_network_all{i,j}{1,1});
            
In <a href="matlab:helpUtils.errorDocCallback('compute_raw_features_s2isa', '/home/legend/ISA_SFA/compute_raw_features_s2isa.m', 36)" style="font-weight:bold">compute_raw_features_s2isa</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/compute_raw_features_s2isa.m',36,0)">line 36</a>)
        [X_clip, motionmeasure, ds_sections] =
        transact_dense_samp(M,params,isa_network_all,sfa_network_all);
        
In <a href="matlab:helpUtils.errorDocCallback('test_features_s2isa', '/home/legend/ISA_SFA/test_features_s2isa.m', 29)" style="font-weight:bold">test_features_s2isa</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/test_features_s2isa.m',29,0)">line 29</a>)
[Xtrain_raw{1}, MM_train{1}, train_indices{1}] =
compute_raw_features_s2isa(params, all_train_files, 1);

In <a href="matlab:helpUtils.errorDocCallback('master_test', '/home/legend/ISA_SFA/master_test.m', 99)" style="font-weight:bold">master_test</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/master_test.m',99,0)">line 99</a>)
test_features_s2isa(params)

In <a href="matlab:helpUtils.errorDocCallback('run', '/home/legend/ISA_SFA/run.m', 2)" style="font-weight:bold">run</a> (<a href="matlab: opentoline('/home/legend/ISA_SFA/run.m',2,0)">line 2</a>)
master_test
} 
run
1
--- Feature extraction and classification (Hollywood2) ---
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 feature size: 250
Start vector quantization on training samples:
total number of training samples: 566434
kmeans on number of samples: 566434
compute kmeans: 1 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 94405688.000000
compute kmeans: 2 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 94448544.000000
compute kmeans: 3 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 94441776.000000
assigning all labels to train data......
assigning all labels to train data......
assigning all labels to train data......
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 assigning all labels to test data......
-----saving at SAVEPATH ..../home/legend/ISA_SFA/  2015-11-04------
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.567100, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.721649, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.613420, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 92% (92/100) (classification)
label = 4,ap = 0.528283, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.052632, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.086714, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.170248, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 87% (87/100) (classification)
label = 8,ap = 0.764442, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.562213, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.322938, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 92% (92/100) (classification)
label = 11,ap = 0.305436, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.523542, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.434885, mean_acc = 91.583333
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.129293, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.735104, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.622294, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.515152, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.055556, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.076923, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.105263, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 87% (87/100) (classification)
label = 8,ap = 0.777609, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 89% (89/100) (classification)
label = 9,ap = 0.487505, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.369562, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.294035, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.436604, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.383742, mean_acc = 91.500000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.049369, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.759129, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.646006, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.562354, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.052632, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.082192, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.105263, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 85% (85/100) (classification)
label = 8,ap = 0.794141, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 89% (89/100) (classification)
label = 9,ap = 0.493350, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.358326, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.265619, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.354986, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.376947, mean_acc = 91.333333
---------------RESULTS---------------
1 th initialization: mean_ap = 0.434885, mean_acc = 91.583333, km_obj = 94405688.000000
2 th initialization: mean_ap = 0.383742, mean_acc = 91.500000, km_obj = 94448544.000000
3 th initialization: mean_ap = 0.376947, mean_acc = 91.333333, km_obj = 94441776.000000
1
--- Feature extraction and classification (Hollywood2) ---
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 feature size: 250
Start vector quantization on training samples:
total number of training samples: 566434
kmeans on number of samples: 566434
compute kmeans: 1 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182378272.000000
compute kmeans: 2 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182260528.000000
compute kmeans: 3 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182335184.000000
assigning all labels to train data......
assigning all labels to train data......
assigning all labels to train data......
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 assigning all labels to test data......
-----saving at SAVEPATH ..../home/legend/ISA_SFA/  2015-11-04------
[Warning: Directory already exists.] 
[> In <a href="matlab: opentoline('/home/legend/ISA_SFA/save_stackisa.m',9,1)">save_stackisa at 9</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/test_features_s2isa.m',52,1)">test_features_s2isa at 52</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/master_test.m',99,1)">master_test at 99</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/run.m',5,1)">run at 5</a>] 
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.024721, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.738123, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.706061, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.518717, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.051020, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.078947, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.095238, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 87% (87/100) (classification)
label = 8,ap = 0.753529, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 89% (89/100) (classification)
label = 9,ap = 0.509747, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.233707, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.316518, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.519428, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.378813, mean_acc = 91.500000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.175889, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.688507, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.719008, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.489627, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.053763, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.085477, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.125097, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 84% (84/100) (classification)
label = 8,ap = 0.744047, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.559636, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.330962, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 92% (92/100) (classification)
label = 11,ap = 0.292585, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.482473, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.395589, mean_acc = 91.250000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.021277, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 91% (91/100) (classification)
label = 2,ap = 0.695795, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.645688, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.531071, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.056180, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.088235, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.105263, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 88% (88/100) (classification)
label = 8,ap = 0.769745, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.525580, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.396226, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.281599, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.578543, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.391267, mean_acc = 91.583333
---------------RESULTS---------------
1 th initialization: mean_ap = 0.378813, mean_acc = 91.500000, km_obj = 182378272.000000
2 th initialization: mean_ap = 0.395589, mean_acc = 91.250000, km_obj = 182260528.000000
3 th initialization: mean_ap = 0.391267, mean_acc = 91.583333, km_obj = 182335184.000000
1
--- Feature extraction and classification (Hollywood2) ---
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 feature size: 250
Start vector quantization on training samples:
total number of training samples: 566434
kmeans on number of samples: 566434
compute kmeans: 1 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182378272.000000
compute kmeans: 2 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182260528.000000
compute kmeans: 3 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182335184.000000
assigning all labels to train data......
assigning all labels to train data......
assigning all labels to train data......
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 assigning all labels to test data......
-----saving at SAVEPATH ..../home/legend/ISA_SFA/  2015-11-04------
[Warning: Directory already exists.] 
[> In <a href="matlab: opentoline('/home/legend/ISA_SFA/save_stackisa.m',9,1)">save_stackisa at 9</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/test_features_s2isa.m',52,1)">test_features_s2isa at 52</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/master_test.m',99,1)">master_test at 99</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/run.m',8,1)">run at 8</a>] 
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.024721, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.738123, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.706061, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.518717, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.051020, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.078947, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.095238, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 87% (87/100) (classification)
label = 8,ap = 0.753529, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 89% (89/100) (classification)
label = 9,ap = 0.509747, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.233707, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.316518, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.519428, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.378813, mean_acc = 91.500000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.175889, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.688507, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.719008, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.489627, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.053763, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.085477, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.125097, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 84% (84/100) (classification)
label = 8,ap = 0.744047, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.559636, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.330962, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 92% (92/100) (classification)
label = 11,ap = 0.292585, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.482473, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.395589, mean_acc = 91.250000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.021277, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 91% (91/100) (classification)
label = 2,ap = 0.695795, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.645688, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.531071, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.056180, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.088235, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.105263, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 88% (88/100) (classification)
label = 8,ap = 0.769745, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.525580, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.396226, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.281599, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.578543, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.391267, mean_acc = 91.583333
---------------RESULTS---------------
1 th initialization: mean_ap = 0.378813, mean_acc = 91.500000, km_obj = 182378272.000000
2 th initialization: mean_ap = 0.395589, mean_acc = 91.250000, km_obj = 182260528.000000
3 th initialization: mean_ap = 0.391267, mean_acc = 91.583333, km_obj = 182335184.000000
1
--- Feature extraction and classification (Hollywood2) ---
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 feature size: 250
Start vector quantization on training samples:
total number of training samples: 566434
kmeans on number of samples: 566434
compute kmeans: 1 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182378272.000000
compute kmeans: 2 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182260528.000000
compute kmeans: 3 th initialization
iterations: 1 2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 
21 22 23 24 25 26 27 28 29 30 
31 32 33 34 35 36 37 38 39 40 
41 42 43 44 45 46 47 48 49 50 

obj value: 182335184.000000
assigning all labels to train data......
assigning all labels to train data......
assigning all labels to train data......
Computing features for all videos in the training set:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 assigning all labels to test data......
-----saving at SAVEPATH ..../home/legend/ISA_SFA/  2015-11-04------
[Warning: Directory already exists.] 
[> In <a href="matlab: opentoline('/home/legend/ISA_SFA/save_stackisa.m',9,1)">save_stackisa at 9</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/test_features_s2isa.m',52,1)">test_features_s2isa at 52</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/master_test.m',99,1)">master_test at 99</a>
  In <a href="matlab: opentoline('/home/legend/ISA_SFA/run.m',11,1)">run at 11</a>] 
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.024721, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.738123, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.706061, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.518717, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.051020, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.078947, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.095238, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 87% (87/100) (classification)
label = 8,ap = 0.753529, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 89% (89/100) (classification)
label = 9,ap = 0.509747, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.233707, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 93% (93/100) (classification)
label = 11,ap = 0.316518, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.519428, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.378813, mean_acc = 91.500000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.175889, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 92% (92/100) (classification)
label = 2,ap = 0.688507, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.719008, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.489627, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.053763, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.085477, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.125097, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 84% (84/100) (classification)
label = 8,ap = 0.744047, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.559636, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.330962, w_neg = 0.549451, w_pos = 5.555556
Accuracy = 92% (92/100) (classification)
label = 11,ap = 0.292585, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 87% (87/100) (classification)
label = 12,ap = 0.482473, w_neg = 0.581395, w_pos = 3.571429
mean_ap = 0.395589, mean_acc = 91.250000
binning VQ labels.... 
unscrambling data.....
normalizing.....
start classfication with chi-squared kernel svm, computing kernel matrices......
Accuracy = 98% (98/100) (classification)
label = 1,ap = 0.021277, w_neg = 0.537634, w_pos = 7.142857
Accuracy = 91% (91/100) (classification)
label = 2,ap = 0.695795, w_neg = 0.595238, w_pos = 3.125000
Accuracy = 95% (95/100) (classification)
label = 3,ap = 0.645688, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 91% (91/100) (classification)
label = 4,ap = 0.531071, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 95% (95/100) (classification)
label = 5,ap = 0.056180, w_neg = 0.526316, w_pos = 10.000000
Accuracy = 94% (94/100) (classification)
label = 6,ap = 0.088235, w_neg = 0.520833, w_pos = 12.500000
Accuracy = 94% (94/100) (classification)
label = 7,ap = 0.105263, w_neg = 0.531915, w_pos = 8.333333
Accuracy = 88% (88/100) (classification)
label = 8,ap = 0.769745, w_neg = 0.609756, w_pos = 2.777778
Accuracy = 90% (90/100) (classification)
label = 9,ap = 0.525580, w_neg = 0.543478, w_pos = 6.250000
Accuracy = 83% (83/100) (classification)
label = 10,ap = 0.396226, w_neg = 0.549